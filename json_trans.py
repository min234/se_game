import pandas as pd
import json
import torch
import re
from transformers import AutoModelForCausalLM, AutoTokenizer

# âœ… Hugging Face DeepSeek ëª¨ë¸ ì‚¬ìš©
model_name = "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B"  # âš¡ ë” ì‘ì€ ëª¨ë¸ì€ "deepseek-ai/deepseek-llm-1.3b" ì‚¬ìš© ê°€ëŠ¥
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(
    model_name, 
    torch_dtype=torch.float16,  # âœ… VRAM ì ˆì•½ (16-bit ì—°ì‚°)
    device_map="auto"           # âœ… GPU ìë™ í• ë‹¹
)

# âœ… ì—‘ì…€ íŒŒì¼ ë¡œë“œ
file_path = "í•œêµ­ì–´_ë‹¨ë°œì„±_ëŒ€í™”_ë°ì´í„°ì…‹.xlsx"
df = pd.read_excel(file_path, engine="openpyxl", dtype=str)

# âœ… JSONL ë°ì´í„° ì €ì¥ ë¦¬ìŠ¤íŠ¸
jsonl_data = []
count = 0  # ğŸ”¹ ì €ì¥ ê°œìˆ˜ ì¹´ìš´íŠ¸ ë³€ìˆ˜

print("ğŸš€ ë°ì´í„° ë³€í™˜ ì‹œì‘...")

for _, row in df.iterrows():
    prompt = row["Sentence"]  # ì§ˆë¬¸ ê°€ì ¸ì˜¤ê¸°
    query = f"ë„ˆëŠ” í•œêµ­ 10ëŒ€ í•™ìƒì´ì•¼. ìì—°ìŠ¤ëŸ½ê³  ì¹œê·¼í•œ ë§íˆ¬ë¡œ ì´ ì§ˆë¬¸ì— ë‹µí•´ì¤˜:\n\n{prompt}"

    # âœ… ë¡œê·¸: í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ ì§ˆë¬¸ ì¶œë ¥
    print(f"\nğŸ”¹ [{count+1}] ì§ˆë¬¸: {prompt}")

    # âœ… í† í¬ë‚˜ì´ì§• (GPUë¡œ ì´ë™)
    inputs = tokenizer(query, return_tensors="pt").to("cuda")

    # âœ… ëª¨ë¸ ì‹¤í–‰ (with torch.no_grad()ë¡œ ë©”ëª¨ë¦¬ ìµœì í™”)
    with torch.no_grad():
        output = model.generate(
            **inputs,
            max_new_tokens=100,  # âœ… ìµœëŒ€ ìƒì„± ê¸¸ì´ ì„¤ì •
            temperature=0.7,      # âœ… ì°½ì˜ì  ëŒ€ë‹µì„ ì›í•˜ë©´ ì¦ê°€
            top_p=0.9,            # âœ… ë†’ì€ í™•ë¥ ì˜ ë‹¨ì–´ë§Œ ì„ íƒ
            repetition_penalty=1.2  # âœ… ë°˜ë³µ ë°©ì§€
        )

    # âœ… ë‹µë³€ ë””ì½”ë”© ë° ë¶ˆí•„ìš”í•œ í…ìŠ¤íŠ¸ ì œê±°
    response = tokenizer.decode(output[0], skip_special_tokens=True).strip()

    # âœ… `<think>` íƒœê·¸ ì œê±°
    response = re.sub(r"<think>.*?</think>", "", response, flags=re.DOTALL).strip()

    # âœ… ì§ˆë¬¸ ë‚´ìš© ì œê±° (ì‘ë‹µì— í¬í•¨ëœ ê²½ìš°)
    if query in response:
        response = response.replace(query, "").strip()

    # âœ… ë¡œê·¸: ìƒì„±ëœ ë‹µë³€ ì¶œë ¥
    print(f"ğŸ’¬ ì •ì œëœ ë‹µë³€: {response}")

    jsonl_data.append({
        "messages": [
            {"role": "user", "content": prompt},
            {"role": "assistant", "content": response}
        ]
    })

    count += 1  # ğŸ”¹ ë³€í™˜ëœ ê°œìˆ˜ ì¦ê°€
    

# âœ… ìµœì¢… JSONL íŒŒì¼ ì €ì¥
jsonl_file = "train_data.jsonl"
with open(jsonl_file, "w", encoding="utf-8") as f:
    for entry in jsonl_data:
        f.write(json.dumps(entry, ensure_ascii=False) + "\n")

# âœ… ìµœì¢… ì €ì¥ëœ ë°ì´í„° ë¡œê·¸ ì¶œë ¥
print("\nâœ… ìµœì¢… JSONL ë°ì´í„° í™•ì¸:")
for entry in jsonl_data:
    print(entry)

print(f"\nâœ… ì´ {count}ê°œ ë°ì´í„° ë³€í™˜ ì™„ë£Œ! íŒŒì¼: {jsonl_file}")
